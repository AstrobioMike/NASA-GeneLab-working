############################################################################################
## Configuration file for GeneLab Illumina metagenomics processing workflow               ##
## Developed by Michael D. Lee (Mike.Lee@nasa.gov)                                        ##
############################################################################################

############################################################
##################### VARIABLES TO SET #####################
############################################################

#############################################################
##### These first 5 need to match what is on our system #####
#############################################################

## single-column file with unique portion of sample names
sample_info_file:
    "unique-sample-names.txt"

## raw reads directory (can be relative to workflow directory, or needs to be full path)
raw_reads_dir:
    "../Raw_Data/"

## raw read suffixes (region following the unique part of the sample names)
  # e.g. for "Sample-1_R1_raw.fastq.gz" would be "_R1_raw.fastq.gz"
raw_R1_suffix:
    "_R1_raw.fastq.gz"
raw_R2_suffix:
    "_R2_raw.fastq.gz"

## root directory of reference databases (or where they will be downloaded if they don't exist yet)
    # this should be provided as a full path (starting with `/` as the below example 
    # (note that the the `~/` home shortcut is not expanded
    # by snakemake's evaluation of files, so don't use that)
REF_DB_ROOT_DIR:
    "/path/to/ref-dbs/"

######################################################################
##### The rest only need to be altered if we want to change them #####
######################################################################

## number of threads to use PER snakemake job (which is set with the -j parameter passed to snakemake call)
    # passed to megahit, bowtie2, samtools, metabat2, checkm-pplacer (many may be running concurrently)
num_threads:
    20

## number of CPUs to use PER snakemake job
    # passed to KOFamScan, CAT, checkm (many may be running concurrently)
num_cpus:
    20

## number of CPUs to use for gtdb-tk (only 1 gtdb-tk job will be run, so not multiplied, but the pplacer step can be more memory intensive with more cpus i think)
gtdb_tk_num_cpus:
    20

## maximum memory allowed passed to megahit assembler
    # can be set either by proportion of available on system, e.g. 0.5
    # or by absolute value in bytes, e.g. 100e9 would be 100 GB
max_mem:
    0.5

## MAG filtering cutoffs based on checkm quality assessments (in percent); see https://github.com/Ecogenomics/CheckM/wiki/Reported-Statistics
minimum_estimated_completion:
    90
maximum_estimated_redundancy:
    10
maximum_estimated_strain_heterogeneity:
    0

## quality trimmed/filtered suffixes
trimmed_R1_suffix:
    "_R1_trimmed.fq.gz"
trimmed_R2_suffix:
    "_R2_trimmed.fq.gz"

trimmed_R1_fastqc_suffix:
    "_R1_trimmed_fastqc.zip"
trimmed_R2_fastqc_suffix:
    "_R2_trimmed_fastqc.zip"

## output directories (all relative to processing directory, will be created)
fastqc_out_dir:
    "../FastQC_Outputs/"
filtered_reads_dir:
    "../Filtered_Sequence_Data/"
assembly_based_dir:
    "../Assembly-based_Processing/"
assemblies_dir:
    "../Assembly-based_Processing/assemblies/"
genes_dir:
    "../Assembly-based_Processing/predicted-genes/"
annotations_and_tax_dir:
    "../Assembly-based_Processing/annotations-and-taxonomy/"
mapping_dir:
    "../Assembly-based_Processing/read-mapping/"
combined_output_dir:
    "../Assembly-based_Processing/combined-outputs/"
bins_dir:
    "../Assembly-based_Processing/bins/"
MAGs_dir:
    "../Assembly-based_Processing/MAGs/"
read_based_dir:
    "../Read-based_Processing/"
logs_dir:
    "logs/"


#######################################################
################# REFERENCE DATABASES #################
#######################################################
# The below variables probably shouldn't be changed unless we really want to for some reason.
# The workflow will check the locations pointed to below and install the databases
# if they are not already there. It looks for the below "TRIGGER" filenames (they 
# all end with "*_DB_SETUP") in the directory for each database, which it creates when
# it sets them up initially. If we want to point to DBs that already exist on our setup,
# we need to add these (empty) files to their respective directories. The
# workflow just checks the file is there to know it doesn't need to setup the DB.
#
# All together, after installed and unpacked, these will take up about 240 GB. But may 
# require up to 500 GB during installation and initial un-packing. 

## specific database locations
KOFAMSCAN_DIR:
    "kofamscan_db"
KOFAMSCAN_TRIGGER_FILE:
    "KO_DB_SETUP"
CAT_DIR:
    "CAT_prepare_20210107"
CAT_DL_FILE:
    "CAT_prepare_20210107.tar.gz"
CAT_DL_LINK:
    "tbb.bio.uu.nl/bastiaan/CAT_prepare/CAT_prepare_20210107.tar.gz"
CAT_TRIGGER_FILE:
    "CAT_DB_SETUP"
CAT_DB:
    "/2021-01-07_CAT_database"
CAT_TAX:
    "/2021-01-07_taxonomy"
GTDB_DATA_PATH:
    "GTDB-tk-ref-db"
GTDB_TRIGGER_FILE:
    "GTDBTK_DB_SETUP"
HUMANN3_DBS_DIR:
    "humann3-db"
HUMANN3_CHOCOPHLAN_TRIGGER_FILE:
    "CHOCOPHLAN_DB_SETUP"
HUMANN3_UNIREF_TRIGGER_FILE:
    "UNIREF_DB_SETUP"
HUMANN3_UTILITY_MAPPING_TRIGGER_FILE:
    "UTILITY_MAPPING_SETUP"
METAPHLAN3_DB_DIR:
    "metaphlan3-db"
METAPHLAN_TRIGGER_FILE:
    "METAPHLAN3_DB_SETUP"
